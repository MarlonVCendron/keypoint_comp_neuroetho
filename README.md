# Neuroetologia Computacional 游

Implementa칞칚o do [Keypoint MoSeq](https://github.com/dattalab/keypoint-moseq) pelo
[LEMCOG](https://sites.google.com/academico.ufpb.br/lemcog).

## Ajuda

Para mais detalhes sobre os comandos dispon칤veis, execute `python -m main -h`.

Para mais detalhes sobre a configura칞칚o do projeto, consulte a [documenta칞칚o do Keypoint MoSeq](https://keypoint-moseq.readthedocs.io).

## Treinando um modelo

Passos para treinar um modelo e gerar os resultados:

##### Ambiente conda

Inicie criando um novo ambiente conda a partir do arquivo `env.yml` e ativando-o:

```sh
conda env create -f env.yml
conda activate keypoint_comp_neuroetho
```

##### Inicializar o projeto

O pr칩ximo passo 칠 inicializar o projeto. Para isso, basta executar o principal comando `python -m main` passando o argumento `init` e o diret칩rio do projeto como argumento.

```sh
python -m main --project-dir <nome_do_projeto> init
```

Isso criar치 o diret칩rio `projects/<nome_do_projeto>` com o arquivo de configura칞칚o `config.yml` e o diret칩rio `data`. Coloque os
v칤deos e dados do DeepLabCut no diret칩rio `data` e atualize o
arquivo `config.yml` com as configura칞칫es necess치rias, principalmente:
- `bodyparts`, `use_bodyparts`, `skeleton`, `anterior_bodyparts`, `posterior-bodyparts` conforme os pontos usados no DeepLabCut.
- `video_dir`: o/os diret칩rio/diret칩rios onde est칚o os v칤deos e dados do DeepLabCut.
- `fps` dos v칤deos.

##### Calibra칞칚o de ru칤do

##### Ajustar PCA

##### Scan do kappa

##### Treinamento do AR

##### Treinamento do AR-HMM









---

#### Conda

##### Criar o ambiente

```sh
conda env create -f env.yml
```


##### Ativar o ambiente

```sh
conda activate keypoint_comp_neuroetho
```


##### Atualizar o ambiente

```sh
conda env update -f env.yml
```

##### Exportar o ambiente

```sh
conda env export --no-builds > env.yml
```

---

##### Limite de mem칩ria

칄 poss칤vel limitar quanta mem칩ria da GPU o JAX pode usar.

```sh
export XLA_PYTHON_CLIENT_MEM_FRACTION=0.5
```
